{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98509a93-9d39-4a1c-81a2-b6e6396b6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae46298d-4383-4ffb-8ed4-9b5290d4d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tchan/repos/datasetGAN_release/datasetGAN/model_dir/new_echo/samples\n",
      "data/2D_synthetic\n"
     ]
    }
   ],
   "source": [
    "sample_dir = os.path.expanduser(\"~\")+'/repos/datasetGAN_release/datasetGAN/model_dir/new_echo/samples'\n",
    "print(sample_dir)\n",
    "save_dir = 'data/2D_synthetic'\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ee572a-fa25-4d40-bf55-aef6de7bc3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:03<00:00, 503.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_path in tqdm(glob.glob(sample_dir + '/*.png')):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    if 'label_' in img_path:\n",
    "        # print('label')\n",
    "        img = cv2.resize(img, dsize=(128, 128)) #bilinear by default\n",
    "        img = np.expand_dims(img, 2)#necessary for nn-unet processing to be in shape of 3d img\n",
    "        newpath = '{}/labelsTr/{}.nii.gz'.format(save_dir, os.path.splitext(os.path.split(img_path)[1])[0].replace('label_',''))\n",
    "    else:\n",
    "        # print('image')\n",
    "        img = np.expand_dims(img, 2)#necessary for nn-unet processing to be in shape of 3d img\n",
    "        img = np.mean(img, axis=3)\n",
    "        newpath = '{}/imagesTr/{}_0000.nii.gz'.format(save_dir, os.path.splitext(os.path.split(img_path)[1])[0])\n",
    "    newimg = nib.Nifti1Image(img, np.eye(4))\n",
    "    nib.save(newimg, newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0418911f-0df2-44b0-b810-07ec5638f85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/2d_synthetic/957'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir + '/' + os.path.splitext(os.path.split(img_path)[1])[0].replace('label_','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fd083-c426-46be-aa56-cb180f1c4fa3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Make dataset.json file\n",
    "\n",
    "task_folder_name is the directory of the task\n",
    "train_dir and test_dir are the paths to the train labels and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a7dada-b2dd-47ae-ade4-010481dca6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json already exist!\n",
      "dataset.json overwritten!\n"
     ]
    }
   ],
   "source": [
    "task_folder_name = os.path.expanduser(\"~\")+'/../../data1/nnUNet_raw/nnUNet_raw_data/Task800_4Chamber'\n",
    "train_dir = task_folder_name+'/labelsTr'\n",
    "test_dir = task_folder_name+'/imagesTs'\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = \"Task800_4Chamber\"\n",
    "    json_dict['description'] = \"segmentation preliminary dataset for 4 chamber synthetic echo\"\n",
    "    json_dict['tensorImageSize'] = \"2D\"\n",
    "    json_dict['reference'] = \"none\"\n",
    "    json_dict['licence'] = \"none\"\n",
    "    json_dict['release'] = \"0.0\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"echo\"\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"one\",\n",
    "        \"2\": \"two\",\n",
    "        \"3\": \"three\",\n",
    "        \"4\": \"four\",\n",
    "        \"5\": \"five\",\n",
    "        \"6\": \"six\",\n",
    "        \"7\": \"seven\",\n",
    "        \"8\": \"eight\",\n",
    "        \"9\": \"nine\",\n",
    "        \"10\": \"ten\",\n",
    "        \"11\": \"eleven\",\n",
    "        \"12\": \"twelve\",\n",
    "        \"13\": \"thirteen\",\n",
    "        \"14\": \"fourteen\"\n",
    "    }\n",
    "    \n",
    "    train_ids = os.listdir(train_dir)\n",
    "    train_ids = sorted([os.path.splitext(os.path.splitext(id)[0])[0] for id in train_ids])\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    test_ids = sorted([os.path.splitext(os.path.splitext(id)[0])[0] for id in test_ids])\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    #no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i in train_ids]\n",
    "    \n",
    "    #removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96101ee4-1bbf-4009-9a94-a76d8c579d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128)\n",
      "(1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#CHECK image size\n",
    "\n",
    "import SimpleITK as sitk\n",
    "print(sitk.GetArrayFromImage(sitk.ReadImage('data/2D_synthetic/imagesTr/0_0000.nii.gz')).shape)\n",
    "print(sitk.GetArrayFromImage(sitk.ReadImage('data/2D_synthetic/labelsTr/0.nii.gz')).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ef8e2-00c2-4a8f-9c12-64295a78d4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
